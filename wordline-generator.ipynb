{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "wordline.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e4tOtuA8c95h",
        "outputId": "4ba90bf0-0efc-4125-989c-c0b09353345e"
      },
      "source": [
        "!curl https://norvig.com/ngrams/count_1w.txt -o count_1w.txt "
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
            "                                 Dload  Upload   Total   Spent    Left  Speed\n",
            "100 4840k  100 4840k    0     0  11.5M      0 --:--:-- --:--:-- --:--:-- 11.5M\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QXUUgTc2gXQw",
        "outputId": "39f36f5f-3ab6-486d-941f-620852d579de"
      },
      "source": [
        "!curl https://raw.githubusercontent.com/first20hours/google-10000-english/master/google-10000-english-no-swears.txt -o top-10000-no-swears.txt"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
            "                                 Dload  Upload   Total   Spent    Left  Speed\n",
            "\r  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0\r 13 75153   13 10508    0     0  61450      0  0:00:01 --:--:--  0:00:01 61093\r100 75153  100 75153    0     0   396k      0 --:--:-- --:--:-- --:--:--  394k\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VH-PAbppgcaM"
      },
      "source": [
        "with open('top-10000-no-swears.txt', 'r') as f:\n",
        "  safe_words = set(list(f.read().splitlines()))"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tMu1jy6Pgq2L",
        "outputId": "abe953d3-7cbe-44ce-d1e0-b0f2ffff499e"
      },
      "source": [
        "len(safe_words)"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "9894"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CykPM4irJBAp"
      },
      "source": [
        "word_to_count = {}\n",
        "\n",
        "with open('count_1w.txt', 'r') as f:\n",
        "  for x in f.readlines():\n",
        "    word, count = x.split()\n",
        "    if word not in safe_words:\n",
        "      continue\n",
        "    if len(word) < 3 or len(word) > 6:\n",
        "      continue\n",
        "\n",
        "    invalid = False\n",
        "    for i in range(len(word)-1):\n",
        "      if word[i] == word[i+1]:\n",
        "        invalid = True\n",
        "        break\n",
        "    if invalid:\n",
        "      continue\n",
        "    word_to_count[word] = int(count)"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1Ma_mewV-hjm"
      },
      "source": [
        "LINE_SIZE = 7\n",
        "DICTIONARY_SIZE = 1000\n",
        "WORD_SIZE = 6\n",
        "FIG_SIZE = 4\n",
        "SIDE_SIZE = 3"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nn8Igl0g-uA9",
        "outputId": "e39cd865-9240-4b91-c7f1-cbe84320b080"
      },
      "source": [
        "!curl https://raw.githubusercontent.com/dwyl/english-words/master/words_dictionary.json -o full_dictionary.json"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
            "                                 Dload  Upload   Total   Spent    Left  Speed\n",
            "100 6665k  100 6665k    0     0  15.1M      0 --:--:-- --:--:-- --:--:-- 15.1M\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aZSkC74l-xyJ"
      },
      "source": [
        "import json\n",
        "  \n",
        "with open('full_dictionary.json') as json_file:\n",
        "    full_dictionary = json.load(json_file)\n",
        "\n",
        "def is_generateable(word, figure):\n",
        "  if len(word) > 6 or len(word) < 3:\n",
        "    return False\n",
        "  for i in range(len(word)-1):\n",
        "    cando = False\n",
        "    for side_j in figure:\n",
        "      for side_k in figure:\n",
        "        if side_j == side_k:\n",
        "          continue\n",
        "        if word[i] in side_j and word[i+1] in side_k:\n",
        "          cando = True\n",
        "          break\n",
        "    if not cando:\n",
        "      return False\n",
        "  return True\n",
        "\n",
        "def get_full_dict(figure):\n",
        "  seed_dict = []\n",
        "  for word in full_dictionary.keys():\n",
        "    if is_generateable(word, figure):\n",
        "      seed_dict.append(word)\n",
        "\n",
        "  return seed_dict"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uX0JSwVwJXUI"
      },
      "source": [
        "import random\n",
        "import numpy as np\n",
        "import string\n",
        "from copy import deepcopy\n",
        "import time\n",
        "\n",
        "rolls = 0\n",
        "st = time.time()\n",
        "while True:\n",
        "  rolls += 1\n",
        "  if rolls % 100 == 0:\n",
        "    print(\"Rolls: {}, Elapsed time: {}\".format(rolls, time.time()-st))\n",
        "  ch = random.choice(string.ascii_lowercase)\n",
        "  res = [ []*3 for i in range(4)]\n",
        "  prev_side = random.choice(list(range(4)))\n",
        "  res[prev_side].append(ch)\n",
        "  charset = set([ch])\n",
        "  past_words = set()\n",
        "\n",
        "  def can_use(chosen_word):\n",
        "    global res, prev_side, charset\n",
        "    modded_res = deepcopy(res)\n",
        "    modded_prev_side = prev_side\n",
        "    modded_charset = deepcopy(charset)\n",
        "    is_first_letter = True\n",
        "    for char in chosen_word:\n",
        "      if char not in modded_charset:\n",
        "        found_side = None\n",
        "        side_ordering = np.random.permutation(list(range(4)))\n",
        "        for side in side_ordering:\n",
        "          if side == modded_prev_side:\n",
        "            continue\n",
        "          if len(modded_res[side]) == 3:\n",
        "            continue\n",
        "          found_side = side\n",
        "          break\n",
        "        if found_side is None:\n",
        "          return False\n",
        "        modded_res[found_side].append(char)\n",
        "        modded_prev_side = found_side\n",
        "        modded_charset.add(char)\n",
        "      else:\n",
        "        for i in range(4):\n",
        "          if char in modded_res[i]:\n",
        "            # print(char, i)\n",
        "            if i == modded_prev_side and not is_first_letter:\n",
        "              return False\n",
        "            modded_prev_side = i\n",
        "      is_first_letter = False\n",
        "    res = modded_res\n",
        "    prev_side = modded_prev_side\n",
        "    charset = modded_charset\n",
        "    past_words.add(chosen_word)\n",
        "    return True\n",
        "\n",
        "\n",
        "  chosen_word_soln = []\n",
        "  while len(charset) < 12 and len(past_words) < 5:\n",
        "    filtered_words = list(filter(lambda x: x.startswith(ch) and x not in past_words, list(word_to_count.keys())))\n",
        "    filtered_weights = [word_to_count[word] for word in filtered_words]\n",
        "    sum_w = sum(filtered_weights)\n",
        "    filtered_weights = [x/sum_w for x in filtered_weights]\n",
        "    chosen_word = None\n",
        "    iter = 0\n",
        "    while (chosen_word is None or not can_use(chosen_word)) and iter < 100:\n",
        "      chosen_word = np.random.choice(filtered_words, p=filtered_weights)\n",
        "      iter += 1\n",
        "    \n",
        "    # print(chosen_word, word_to_count[chosen_word])\n",
        "    chosen_word_soln.append(chosen_word)\n",
        "    ch = chosen_word[-1]\n",
        "\n",
        "  def is_figure_nice(figure):\n",
        "    if len(figure) != FIG_SIZE:\n",
        "      return False\n",
        "    for side in figure:\n",
        "      if len(side) != SIDE_SIZE:\n",
        "        return False\n",
        "    \n",
        "    return True\n",
        "\n",
        "  figure = list([list(np.random.permutation(x)) for x in res])\n",
        "  if not is_figure_nice(figure):\n",
        "    continue\n",
        "  dict_size = len(get_full_dict(figure))\n",
        "  if dict_size > DICTIONARY_SIZE:\n",
        "    continue\n",
        "  print(\"Natural soln: {}\".format(chosen_word_soln))\n",
        "  print(\"Figure: {}\".format(figure))\n",
        "  print(\"Dict size: {}\".format(dict_size))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UBN-uRCVazEL"
      },
      "source": [
        "# bad game seeds\n",
        "bad_seeds = [\n",
        "    {\n",
        "        'figure': [['e', 'o', 'a'], ['n', 'l', 't'], ['r', 's', 'g'], ['v', 'i', 'd']],\n",
        "        'solution': ['starting', 'gold', 'design', 'national', 'live'],\n",
        "    },\n",
        "    {\n",
        "        'figure': [['c', 'e', 'y'], ['p', 'l', 'o'], ['i', 'u', 't'], ['v', 'm', 'r']],\n",
        "        'solution': ['improve', 'electric', 'city', 'your'],\n",
        "    },\n",
        "    {\n",
        "        'figure': [['i', 'n', 'e'], ['m', 'r', 's'], ['t', 'u', 'f'], ['o', 'd', 'l']],\n",
        "        'solution': ['for', 'results', 'stories', 'some', 'end'],\n",
        "    },\n",
        "    {\n",
        "        'figure': [['a', 's', 'e'], ['c', 'i', 'p'], ['t', 'l', 'n'], ['b', 'd', 'm']],\n",
        "        'solution': ['dance', 'email', 'labs', 'split'],\n",
        "    },    \n",
        "    {\n",
        "        'figure': [['l', 'c', 'f'], ['i', 'o', 'h'], ['b', 'p', 'e'], ['u', 'r', 'a']],\n",
        "        'solution': ['blue', 'each', 'help', 'profile'],\n",
        "    }\n",
        "]"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QLmWL_CwC6uA"
      },
      "source": [
        "# good game seeds\n",
        "good_seeds = [\n",
        "    {\n",
        "        'figure': [['l', 'u', 'k'], ['r', 'm', 'i'], ['s', 'c', 'n'], ['o', 'g', 'f']],\n",
        "        'line': ['from', 'music', 'click', 'king'],\n",
        "    },\n",
        "    {\n",
        "        'figure': [['i', 'y', 'n'], ['k', 'v', 'u'], ['t', 'e', 'r'], ['o', 'c', 'h']],\n",
        "        'line': ['the', 'entry', 'your', 'river', 'rock'],\n",
        "    },\n",
        "]\n",
        "\n",
        "for seed in good_seeds:\n",
        "  seed['dict'] = get_full_dict(seed['figure'])"
      ],
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2_L2MgcDDZc4"
      },
      "source": [
        "def get_poly_hash(wordlist):\n",
        "  res = 0\n",
        "  for val in wordlist:\n",
        "    res = res*32 + val\n",
        "  return res\n",
        "\n",
        "def string_to_hash(word, req_len):\n",
        "  res = []\n",
        "  for ch in word:\n",
        "\n",
        "    res.append(ord(ch) - ord('a'))\n",
        "\n",
        "  while len(res) < req_len:\n",
        "    res.append(27)\n",
        "  return get_poly_hash(res)\n",
        "\n",
        "def get_computer_readable_form(seed):\n",
        "  # Verify conditions\n",
        "  assert len(seed['figure']) == FIG_SIZE\n",
        "  for side in seed['figure']:\n",
        "    assert len(side) == SIDE_SIZE\n",
        "  \n",
        "  assert len(seed['dict']) <= DICTIONARY_SIZE\n",
        "  for word in seed['dict']:\n",
        "    assert len(word) <= WORD_SIZE\n",
        "\n",
        "  assert len(seed['line']) <= LINE_SIZE\n",
        "  \n",
        "  def get_padding(req_len):\n",
        "    return get_poly_hash([28]*req_len)  \n",
        "  comp_dictionary = [string_to_hash(word, WORD_SIZE) for word in seed['dict']]\n",
        "  while len(comp_dictionary) < DICTIONARY_SIZE:\n",
        "    comp_dictionary.append(get_padding(WORD_SIZE))\n",
        "  \n",
        "  comp_line = [string_to_hash(word, WORD_SIZE) for word in seed['line']]\n",
        "  while len(comp_line) < LINE_SIZE:\n",
        "    comp_line.append(get_padding(WORD_SIZE))          \n",
        "  return {\n",
        "      'dictionary': comp_dictionary,\n",
        "      'line': comp_line,\n",
        "  }"
      ],
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mYfoi1UxLnMa"
      },
      "source": [
        "import json\n",
        "\n",
        "comp_form = get_computer_readable_form(good_seeds[0])\n",
        "\n",
        "with open(\"seed.json\", \"w\") as outfile:\n",
        "    json.dump(comp_form, outfile)"
      ],
      "execution_count": 49,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4-uUmapDOgOi",
        "outputId": "1f48b756-7631-41ad-9c89-aaba76c0f35d"
      },
      "source": [
        "string_to_hash('from', 6)"
      ],
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "186069883"
            ]
          },
          "metadata": {},
          "execution_count": 50
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uBOSxSB0TV5F"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}